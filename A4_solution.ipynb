{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "A4-solution.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/armandordorica/ECE1513_A5_Adversarial_training/blob/master/A4_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pxMUmlEENLXc"
      },
      "source": [
        "Let's first get the imports out of the way."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v0yDWKUrCBiX",
        "colab": {}
      },
      "source": [
        "import array\n",
        "import gzip\n",
        "import itertools\n",
        "import numpy\n",
        "import numpy.random as npr\n",
        "import os\n",
        "import struct\n",
        "import time\n",
        "from os import path\n",
        "import urllib.request\n",
        "\n",
        "import jax.numpy as np\n",
        "from jax.api import jit, grad\n",
        "from jax.config import config\n",
        "from jax.scipy.special import logsumexp\n",
        "from jax import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nIp--T57NGrU"
      },
      "source": [
        "The following cell contains boilerplate code to download and load MNIST data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Du24u5vtDEIn",
        "colab": {}
      },
      "source": [
        "_DATA = \"/tmp/\"\n",
        "\n",
        "def _download(url, filename):\n",
        "  \"\"\"Download a url to a file in the JAX data temp directory.\"\"\"\n",
        "  if not path.exists(_DATA):\n",
        "    os.makedirs(_DATA)\n",
        "  out_file = path.join(_DATA, filename)\n",
        "  if not path.isfile(out_file):\n",
        "    urllib.request.urlretrieve(url, out_file)\n",
        "    print(\"downloaded {} to {}\".format(url, _DATA))\n",
        "\n",
        "\n",
        "def _partial_flatten(x):\n",
        "  \"\"\"Flatten all but the first dimension of an ndarray.\"\"\"\n",
        "  return numpy.reshape(x, (x.shape[0], -1))\n",
        "\n",
        "\n",
        "def _one_hot(x, k, dtype=numpy.float32):\n",
        "  \"\"\"Create a one-hot encoding of x of size k.\"\"\"\n",
        "  return numpy.array(x[:, None] == numpy.arange(k), dtype)\n",
        "\n",
        "\n",
        "def mnist_raw():\n",
        "  \"\"\"Download and parse the raw MNIST dataset.\"\"\"\n",
        "  # CVDF mirror of http://yann.lecun.com/exdb/mnist/\n",
        "  base_url = \"https://storage.googleapis.com/cvdf-datasets/mnist/\"\n",
        "\n",
        "  def parse_labels(filename):\n",
        "    with gzip.open(filename, \"rb\") as fh:\n",
        "      _ = struct.unpack(\">II\", fh.read(8))\n",
        "      return numpy.array(array.array(\"B\", fh.read()), dtype=numpy.uint8)\n",
        "\n",
        "  def parse_images(filename):\n",
        "    with gzip.open(filename, \"rb\") as fh:\n",
        "      _, num_data, rows, cols = struct.unpack(\">IIII\", fh.read(16))\n",
        "      return numpy.array(array.array(\"B\", fh.read()),\n",
        "                      dtype=numpy.uint8).reshape(num_data, rows, cols)\n",
        "\n",
        "  for filename in [\"train-images-idx3-ubyte.gz\", \"train-labels-idx1-ubyte.gz\",\n",
        "                   \"t10k-images-idx3-ubyte.gz\", \"t10k-labels-idx1-ubyte.gz\"]:\n",
        "    _download(base_url + filename, filename)\n",
        "\n",
        "  train_images = parse_images(path.join(_DATA, \"train-images-idx3-ubyte.gz\"))\n",
        "  train_labels = parse_labels(path.join(_DATA, \"train-labels-idx1-ubyte.gz\"))\n",
        "  test_images = parse_images(path.join(_DATA, \"t10k-images-idx3-ubyte.gz\"))\n",
        "  test_labels = parse_labels(path.join(_DATA, \"t10k-labels-idx1-ubyte.gz\"))\n",
        "\n",
        "  return train_images, train_labels, test_images, test_labels\n",
        "\n",
        "\n",
        "def mnist(create_outliers=False):\n",
        "  \"\"\"Download, parse and process MNIST data to unit scale and one-hot labels.\"\"\"\n",
        "  train_images, train_labels, test_images, test_labels = mnist_raw()\n",
        "\n",
        "  train_images = _partial_flatten(train_images) / numpy.float32(255.)\n",
        "  test_images = _partial_flatten(test_images) / numpy.float32(255.)\n",
        "  train_labels = _one_hot(train_labels, 10)\n",
        "  test_labels = _one_hot(test_labels, 10)\n",
        "\n",
        "  if create_outliers:\n",
        "    mum_outliers = 30000\n",
        "    perm = numpy.random.RandomState(0).permutation(mum_outliers)\n",
        "    train_images[:mum_outliers] = train_images[:mum_outliers][perm]\n",
        "\n",
        "  return train_images, train_labels, test_images, test_labels\n",
        "\n",
        "def shape_as_image(images, labels, dummy_dim=False):\n",
        "  target_shape = (-1, 1, 28, 28, 1) if dummy_dim else (-1, 28, 28, 1)\n",
        "  return np.reshape(images, target_shape), labels\n",
        "\n",
        "train_images, train_labels, test_images, test_labels = mnist(create_outliers=False)\n",
        "num_train = train_images.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LdTKppnqIHeV"
      },
      "source": [
        "# **Problem 1**\n",
        "\n",
        "This function computes the output of a fully-connected neural network (i.e., multilayer perceptron) by iterating over all of its layers and:\n",
        "\n",
        "1. taking the `activations` of the previous layer (or the input itself for the first hidden layer) to compute the `outputs` of a linear classifier. Recall the lectures: `outputs` is what we wrote $z=w\\cdot x + b$ where $x$ is the input to the linear classifier. \n",
        "2. applying a non-linear activation. Here we will use $tanh$.\n",
        "\n",
        "Complete the following cell to compute `outputs` and `activations`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blY_DdYdZtu7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bde44dc0-8a34-4260-ad0b-9b476c9f4adc"
      },
      "source": [
        "train_images.shape"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUv8dmqtY_pe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb96d9e0-5120-46a5-fc48-0a5e9e110469"
      },
      "source": [
        "train_images[0].shape"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoSCFntkWhyB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "a = np.reshape(train_images[15], [28,28])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMSiZhu5ZJmP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "bec97628-d1c2-44a2-fb82-b0b14783bbc8"
      },
      "source": [
        "plt.imshow(a, cmap='Greys_r')"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f12643e9c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uX-juqIbdH1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2e4377f6-7969-4c1d-9e5f-04c5b975f061"
      },
      "source": [
        "int_train_labels = np.argmax(train_labels, axis=1)\n",
        "int_train_labels.shape"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ns0vCDwydOb-",
        "colab_type": "text"
      },
      "source": [
        "**Get all the indexes of the training data that were classified as 7**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7L3WkmLscvzL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "int_train_labels_list = list(int_train_labels)\n",
        "indexes_7 = [index for index in range(len(int_train_labels_list)) if int_train_labels_list[index] == 7]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9SnFBzsf3vL",
        "colab_type": "text"
      },
      "source": [
        "**Sample 5 examples from the train data where it is labeled as a 7**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnH5R3U_dnZ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from random import sample\n",
        "sample_indexes= sample(indexes_7,5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpKHA5QaeMtT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b3f9be85-b705-4e68-ef79-b09d316b35b7"
      },
      "source": [
        "sample_indexes"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[58425, 9878, 3189, 51126, 11137]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvPErN4zdatg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "outputId": "7e02e167-1a1a-4c58-a259-d88ae103923d"
      },
      "source": [
        "plt.figure(figsize=(50, 50))\n",
        "for i in range(0,len(sample_indexes)):\n",
        "  print(sample_indexes[i])\n",
        "  index = sample_indexes[i]\n",
        "  a = np.reshape(train_images[index], [28,28])\n",
        "  plt.subplot(int(len(sample_indexes)/6)+1, 6, i+1)\n",
        "  plt.imshow(a, cmap='Greys_r')"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "58425\n",
            "9878\n",
            "3189\n",
            "51126\n",
            "11137\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAACSkAAAGtCAYAAADwe2MJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlUNKAAAAAAAAAADAqP4P+JhoTllmX78AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 3600x3600 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQIeKINFdarn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_sample_sevens(num_of_samples):\n",
        "  int_train_labels = np.argmax(train_labels, axis=1)\n",
        "  int_train_labels_list = list(int_train_labels)\n",
        "  indexes_7 = [index for index in range(len(int_train_labels_list)) if int_train_labels_list[index] == 7]\n",
        "  sample_indexes= sample(indexes_7,num_of_samples)\n",
        "\n",
        "  plt.figure(figsize=(30, 30))\n",
        "  for i in range(0,len(sample_indexes)):\n",
        "    # print(sample_indexes[i])\n",
        "    index = sample_indexes[i]\n",
        "    a = np.reshape(train_images[index], [28,28])\n",
        "    plt.subplot(int(len(sample_indexes)/10)+1, 10, i+1)\n",
        "    plt.imshow(a, cmap='Greys_r')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUXGMmDqdapT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "8e7f650d-038b-40f0-a508-a3766ad0a820"
      },
      "source": [
        "train_sample_sevens(7)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABK0AAACuCAYAAAD04v5vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 2160x2160 with 7 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PGU4xK-iHjhx",
        "colab": {}
      },
      "source": [
        "def predict(params, inputs):\n",
        "  activations = inputs\n",
        "  for w, b in params[:-1]:\n",
        "    outputs = np.dot(activations, w) + b\n",
        "    activations = np.tanh(outputs)\n",
        "  final_w, final_b = params[-1]\n",
        "  logits = np.dot(activations, final_w) + final_b\n",
        "  return logits - logsumexp(logits, axis=1, keepdims=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UgE_NBb9JNDI"
      },
      "source": [
        "The following cell computes the loss of our model. Here we are using cross-entropy combined with a softmax but the implementation uses the `LogSumExp` trick for numerical stability. This is why our previous function `predict` returns the logits to which we substract the `logsumexp` of logits. We discussed this in class but you can read more about it [here](https://blog.feedly.com/tricks-of-the-trade-logsumexp/).\n",
        "\n",
        "Complete the return line. Recall that the loss is defined as :\n",
        "$$ l(X, Y) = -\\frac{1}{n} \\sum_{i\\in 1..n}  \\sum_{j\\in 1.. K}y_j^{(i)} \\log(f_j(x^{(i)})) = -\\frac{1}{n} \\sum_{i\\in 1..n}  \\sum_{j\\in 1.. K}y_j^{(i)} \\log\\left(\\frac{z_j^{(i)}}{\\sum_{k\\in 1..K}z_k^{(i)}}\\right) $$\n",
        "where $X$ is a matrix containing a batch of $n$ training inputs, and $Y$ a matrix containing a batch of one-hot encoded labels defined over $K$ labels. Here $z_j^{(i)}$ is the logits (i.e., input to the softmax) of the model on the example $i$ of our batch of training examples $X$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JlgdP72hH9ly",
        "colab": {}
      },
      "source": [
        "def loss(params, batch):\n",
        "  inputs, targets = batch\n",
        "  preds = predict(params, inputs)\n",
        "  return -np.mean((np.sum(targets*preds,axis=1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ILZ-q5PTMohU"
      },
      "source": [
        "The following cell defines the accuracy of our model and how to initialize its parameters. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UDjCuIGzIAjf",
        "colab": {}
      },
      "source": [
        "def accuracy(params, batch):\n",
        "  inputs, targets = batch\n",
        "  target_class = np.argmax(targets, axis=1)\n",
        "  predicted_class = np.argmax(predict(params, inputs), axis=1)\n",
        "  return np.mean(predicted_class == target_class)\n",
        "\n",
        "def init_random_params(layer_sizes, rng=npr.RandomState(0)):\n",
        "  scale = 0.1\n",
        "  return [(scale * rng.randn(m, n), scale * rng.randn(n))\n",
        "          for m, n, in zip(layer_sizes[:-1], layer_sizes[1:])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "as46_qd5NWMA"
      },
      "source": [
        "The following line defines our architecture with the number of neurons contained in each fully-connected layer (the first layer has 784 neurons because MNIST images are 28*28=784 pixels and the last layer has 10 neurons because MNIST has 10 classes)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MZzv-4dHNV4D",
        "colab": {}
      },
      "source": [
        "#Good fit\n",
        "layer_sizes = [784, 1024, 128, 10]\n",
        "\n",
        "# underfits \n",
        "#layer_sizes = [784, 4, 2, 10]\n",
        "\n",
        "# overfits\n",
        "#layer_sizes = [784, 1024, 1024, 1024, 1024, 128, 10]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PKroKJ6TOETY"
      },
      "source": [
        "The following cell creates a Python generator for our dataset. It outputs one batch of $n$ training examples at a time. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_6lLT1klOMIn",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "num_complete_batches, leftover = divmod(num_train, batch_size)\n",
        "num_batches = num_complete_batches + bool(leftover)\n",
        "\n",
        "def data_stream():\n",
        "  rng = npr.RandomState(0)\n",
        "  while True:\n",
        "    perm = rng.permutation(num_train)\n",
        "    for i in range(num_batches):\n",
        "      batch_idx = perm[i * batch_size:(i + 1) * batch_size]\n",
        "      yield train_images[batch_idx], train_labels[batch_idx]\n",
        "batches = data_stream()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Lm-UbcYZOOci"
      },
      "source": [
        "We are now ready to define our optimizer. Here we use mini-batch stochastic gradient descent. Complete `<w UPDATE RULE>` and `<b UPDATE RULE>` using the update rule we saw in class. Recall that `dw` is the partial derivative of the `loss` with respect to `w` and `learning_rate` is the learning rate of gradient descent. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z8EktCm-OvFh",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.1\n",
        "# oscillates but converges for e.g. 0.5 and doesn't converge for 1.5\n",
        "\n",
        "@jit\n",
        "def update(params, batch):\n",
        "  grads = grad(loss)(params, batch)\n",
        "  return [(w - learning_rate * dw, b - learning_rate* db)\n",
        "          for (w, b), (dw, db) in zip(params, grads)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Tqo4M7uNOvzo"
      },
      "source": [
        "This is now the proper training loop for our fully-connected neural network. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fgrHTrafDHAE",
        "outputId": "c99d37d5-5d00-4c25-a844-768d852bbb91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        }
      },
      "source": [
        "num_epochs = 10\n",
        "params = init_random_params(layer_sizes)\n",
        "for epoch in range(num_epochs):\n",
        "  start_time = time.time()\n",
        "  for _ in range(num_batches):\n",
        "    params = update(params, next(batches))\n",
        "  epoch_time = time.time() - start_time\n",
        "\n",
        "  train_acc = accuracy(params, (train_images, train_labels))\n",
        "  test_acc = accuracy(params, (test_images, test_labels))\n",
        "  print(\"Epoch {} in {:0.2f} sec\".format(epoch, epoch_time))\n",
        "  print(\"Training set accuracy {}\".format(train_acc))\n",
        "  print(\"Test set accuracy {}\".format(test_acc))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 in 3.82 sec\n",
            "Training set accuracy 0.9401500225067139\n",
            "Test set accuracy 0.9377000331878662\n",
            "Epoch 1 in 0.47 sec\n",
            "Training set accuracy 0.9592833518981934\n",
            "Test set accuracy 0.95250004529953\n",
            "Epoch 2 in 0.45 sec\n",
            "Training set accuracy 0.9681666493415833\n",
            "Test set accuracy 0.9607000350952148\n",
            "Epoch 3 in 0.46 sec\n",
            "Training set accuracy 0.9759166836738586\n",
            "Test set accuracy 0.9663000702857971\n",
            "Epoch 4 in 0.45 sec\n",
            "Training set accuracy 0.9795500040054321\n",
            "Test set accuracy 0.9676000475883484\n",
            "Epoch 5 in 0.44 sec\n",
            "Training set accuracy 0.982616662979126\n",
            "Test set accuracy 0.970300018787384\n",
            "Epoch 6 in 0.44 sec\n",
            "Training set accuracy 0.9865833520889282\n",
            "Test set accuracy 0.9716000556945801\n",
            "Epoch 7 in 0.46 sec\n",
            "Training set accuracy 0.9892333149909973\n",
            "Test set accuracy 0.9736000299453735\n",
            "Epoch 8 in 0.44 sec\n",
            "Training set accuracy 0.9911666512489319\n",
            "Test set accuracy 0.9741000533103943\n",
            "Epoch 9 in 0.45 sec\n",
            "Training set accuracy 0.992983341217041\n",
            "Test set accuracy 0.9746000170707703\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s9yFvjncWk8G"
      },
      "source": [
        "# **Problem 2**\n",
        "\n",
        "Before we get started, we need to import two small libraries that contain boilerplate code for common neural network layer types and for optimizers like mini-batch SGD."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tvLxNfXtXCRb",
        "colab": {}
      },
      "source": [
        "from jax.experimental import optimizers\n",
        "from jax.experimental import stax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nNwMlXqfXI8G"
      },
      "source": [
        "Here is a fully-connected neural network architecture, like the one of Problem 1, but this time defined with `stax`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y4wu1XqFds4X",
        "colab": {}
      },
      "source": [
        "init_random_params, predict = stax.serial(\n",
        "    stax.Conv(128, (8,8), padding='valid', strides=(2,2)),\n",
        "    stax.MaxPool((2,2),(1,1)),\n",
        "    stax.Conv(128, (4,4), padding='valid', strides=(2,2)),\n",
        "    stax.Relu,\n",
        "    stax.MaxPool((2,2),(1,1)),\n",
        "    stax.Flatten,\n",
        "    stax.Dense(32),\n",
        "    stax.Relu,\n",
        "    stax.Dense(10)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nEW_OcOCdwFX"
      },
      "source": [
        "We redefine the cross-entropy loss for this model. As done in Problem 1, complete the return line below (it's identical). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zQEeOtAEdvYn",
        "colab": {}
      },
      "source": [
        "def loss(params, batch):\n",
        "  inputs, targets = batch\n",
        "  logits = predict(params, inputs)\n",
        "  preds  = stax.logsoftmax(logits)\n",
        "  return -(1/preds.shape[0])*np.sum(targets * preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8ZBxTvCweJbN"
      },
      "source": [
        "Next, we define the mini-batch SGD optimizer, this time with the optimizers library in JAX. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "peG-cAZ0eGTG",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.15\n",
        "opt_init, opt_update, get_params = optimizers.sgd(learning_rate)\n",
        "\n",
        "@jit\n",
        "def update(_, i, opt_state, batch):\n",
        "  params = get_params(opt_state)\n",
        "  return opt_update(i, grad(loss)(params, batch), opt_state)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gVx2h8lqeoTD"
      },
      "source": [
        "The next cell contains our training loop, very similar to Problem 1. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "41Y6wwFzb-mk",
        "outputId": "ee545c3d-d6d3-41e3-e2c7-ca742622073d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "num_epochs = 12\n",
        "\n",
        "key = random.PRNGKey(123)\n",
        "_, init_params = init_random_params(key, (-1, 28, 28, 1))\n",
        "opt_state = opt_init(init_params)\n",
        "itercount = itertools.count()\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "  for _ in range(num_batches):\n",
        "    opt_state = update(key, next(itercount), opt_state, shape_as_image(*next(batches)))\n",
        "\n",
        "  params = get_params(opt_state)\n",
        "  test_acc = accuracy(params, shape_as_image(test_images, test_labels))\n",
        "  test_loss = loss(params, shape_as_image(test_images, test_labels))\n",
        "  print('Test set loss, accuracy (%): ({:.2f}, {:.2f})'.format(test_loss, 100 * test_acc))\n",
        "\n",
        "  "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set loss, accuracy (%): (0.07, 97.78)\n",
            "Test set loss, accuracy (%): (0.04, 98.59)\n",
            "Test set loss, accuracy (%): (0.04, 98.75)\n",
            "Test set loss, accuracy (%): (0.03, 99.10)\n",
            "Test set loss, accuracy (%): (0.04, 98.78)\n",
            "Test set loss, accuracy (%): (0.03, 99.14)\n",
            "Test set loss, accuracy (%): (0.03, 99.10)\n",
            "Test set loss, accuracy (%): (0.03, 99.12)\n",
            "Test set loss, accuracy (%): (0.03, 99.12)\n",
            "Test set loss, accuracy (%): (0.02, 99.17)\n",
            "Test set loss, accuracy (%): (0.03, 99.09)\n",
            "Test set loss, accuracy (%): (0.04, 98.74)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBOGFto7OvMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}